{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7GfgRLBX5YLe+6AXBBxJr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thiagohrcosta/ML-Number/blob/main/ml_number.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXF2WBa75rgi",
        "outputId": "75a032aa-6e35-435e-aee2-1bb75e12dc07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting utils\n",
            "  Downloading utils-1.0.2.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: utils\n",
            "  Building wheel for utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for utils: filename=utils-1.0.2-py2.py3-none-any.whl size=13906 sha256=85bb3ca89bf52575eefb7994c509299854002ac79cfc8eb8c423ec2be193a74e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/39/f5/9d0ca31dba85773ececf0a7f5469f18810e1c8a8ed9da28ca7\n",
            "Successfully built utils\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install utils\n",
        "import numpy\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, InputLayer\n",
        "from keras.layers import Dropout\n",
        "from keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the Mnist dataset from Keras\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "6xSez_AI7ChQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e8d05ef-5da6-4336-dfee-02232849a90e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the vector size\n",
        "print(X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7Un9WWS8J_s",
        "outputId": "6ad2180e-8611-42eb-92ce-08abb5f75012"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_image = X_train[1000]\n",
        "first_image = numpy.array(first_image, dtype='float')\n",
        "pixels = first_image.reshape((28, 28))\n",
        "plt.imshow(pixels, cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "M_sg7v188LWe",
        "outputId": "6be5b684-a122-4efa-e607-b1ad85014fe1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbrklEQVR4nO3df2xV9f3H8ddtgStqe1mp7e3lZwEFIz+WoXQNyheloe02IooLOpPhxjS41k07Zemmom5JlSWTuTBclgXGJqgkApMsLFhtyVyLaYExo2toV0cNbZl13AuFFtZ+vn8Q77zSgudyb99teT6ST9J7znnf8+7H431x7j091+eccwIAYIClWDcAALg8EUAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwMcK6gc/q7e3V0aNHlZaWJp/PZ90OAMAj55xOnDihUCiklJT+z3MGXQAdPXpUEyZMsG4DAHCJWlpaNH78+H7XD7q34NLS0qxbAAAkwMVez5MWQOvXr9fkyZN1xRVXKC8vT++8887nquNtNwAYHi72ep6UAHrllVdUVlamNWvWaP/+/ZozZ44KCwt17NixZOwOADAUuSSYN2+eKykpiT7u6elxoVDIVVRUXLQ2HA47SQwGg8EY4iMcDl/w9T7hZ0BnzpxRfX29CgoKostSUlJUUFCgmpqa87bv7u5WJBKJGQCA4S/hAfTRRx+pp6dH2dnZMcuzs7PV1tZ23vYVFRUKBALRwRVwAHB5ML8Krry8XOFwODpaWlqsWwIADICE/x1QZmamUlNT1d7eHrO8vb1dwWDwvO39fr/8fn+i2wAADHIJPwMaNWqU5s6dq8rKyuiy3t5eVVZWKj8/P9G7AwAMUUm5E0JZWZlWrFihG2+8UfPmzdO6devU2dmpb33rW8nYHQBgCEpKAC1fvlz//ve/9eSTT6qtrU1f/OIXtXv37vMuTAAAXL58zjln3cSnRSIRBQIB6zYAAJcoHA4rPT293/XmV8EBAC5PBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEyMsG4AuBxNmzbNc833vvc9zzWlpaWeayTJ5/N5rvnvf//rueY73/mO55qtW7d6rjlz5oznGiQfZ0AAABMEEADARMID6KmnnpLP54sZM2bMSPRuAABDXFI+A7rhhhv0xhtv/G8nI/ioCQAQKynJMGLECAWDwWQ8NQBgmEjKZ0CHDx9WKBTSlClTdO+99+rIkSP9btvd3a1IJBIzAADDX8IDKC8vT5s2bdLu3bu1YcMGNTc365ZbbtGJEyf63L6iokKBQCA6JkyYkOiWAACDUMIDqLi4WF//+tc1e/ZsFRYW6k9/+pOOHz+uV199tc/ty8vLFQ6Ho6OlpSXRLQEABqGkXx0wZswYXXfddWpsbOxzvd/vl9/vT3YbAIBBJul/B3Ty5Ek1NTUpJycn2bsCAAwhCQ+gRx99VNXV1frggw/017/+VXfccYdSU1N1zz33JHpXAIAhLOFvwX344Ye655571NHRoWuuuUY333yzamtrdc011yR6VwCAIcznnHPWTXxaJBJRIBCwbgOXqdTUVM813/zmNz3XPPfcc55rMjMzPdfE69ixY55rsrKyktDJ+a699lrPNU1NTUnoBBcTDoeVnp7e73ruBQcAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMBE0r+QDrAQ79d/zJ0713NNWVlZXPvyaseOHZ5r1q9fH9e+4rl558svv+y5Zt68eZ5rfvOb33iuue222zzXIPk4AwIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmPA555x1E58WiUQUCASs28AgUlpa6rnmF7/4RVz78vl8nms6Ojo81xQVFXmu2b9/v+eagfzf++qrr/ZcE4lEPNfE8zvNnz/fc40k1dbWxlWHc8LhsNLT0/tdzxkQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEyOsG8DlJZ4bVsZzM9J4bioqSZ2dnZ5rvva1r3muqa+v91wz2J05c8Zzzfvvv++55vrrr/dcg8GJMyAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmuBkpBlRaWprnmuuuuy4JnfRt3bp1nmv27duX+EaGoHhuRvr3v//dcw03Ix0+OAMCAJgggAAAJjwH0N69e7VkyRKFQiH5fD7t2LEjZr1zTk8++aRycnI0evRoFRQU6PDhw4nqFwAwTHgOoM7OTs2ZM0fr16/vc/3atWv1wgsv6MUXX9S+fft01VVXqbCwUF1dXZfcLABg+PB8EUJxcbGKi4v7XOec07p16/T444/r9ttvlyRt3rxZ2dnZ2rFjh+6+++5L6xYAMGwk9DOg5uZmtbW1qaCgILosEAgoLy9PNTU1fdZ0d3crEonEDADA8JfQAGpra5MkZWdnxyzPzs6OrvusiooKBQKB6JgwYUIiWwIADFLmV8GVl5crHA5HR0tLi3VLAIABkNAACgaDkqT29vaY5e3t7dF1n+X3+5Wenh4zAADDX0IDKDc3V8FgUJWVldFlkUhE+/btU35+fiJ3BQAY4jxfBXfy5Ek1NjZGHzc3N+vgwYPKyMjQxIkT9fDDD+unP/2prr32WuXm5uqJJ55QKBTS0qVLE9k3AGCI8xxAdXV1uvXWW6OPy8rKJEkrVqzQpk2btHr1anV2duqBBx7Q8ePHdfPNN2v37t264oorEtc1AGDI8xxACxculHOu3/U+n0/PPPOMnnnmmUtqDMPT2LFjB2Q/nZ2dcdVt3LgxwZ0A6I/5VXAAgMsTAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMCE57thA5firrvuGpD9vPrqq3HV/fOf/0xwJwD6wxkQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE9yMFHEbO3as55qVK1cmoZPz1dXVDch+8D9+v99zzfz585PQCYYKzoAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCY4GakiNv06dM914wbNy4JnZzv448/HpD94H9SU1M918RzPHR1dXmuOX36tOcaJB9nQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAExwM1IMS3/84x+tW0CSNDY2eq7529/+loROcKk4AwIAmCCAAAAmPAfQ3r17tWTJEoVCIfl8Pu3YsSNm/X333SefzxczioqKEtUvAGCY8BxAnZ2dmjNnjtavX9/vNkVFRWptbY2OrVu3XlKTAIDhx/NFCMXFxSouLr7gNn6/X8FgMO6mAADDX1I+A6qqqlJWVpamT5+uBx98UB0dHf1u293drUgkEjMAAMNfwgOoqKhImzdvVmVlpZ577jlVV1eruLhYPT09fW5fUVGhQCAQHRMmTEh0SwCAQSjhfwd09913R3+eNWuWZs+eralTp6qqqkqLFi06b/vy8nKVlZVFH0ciEUIIAC4DSb8Me8qUKcrMzOz3j8f8fr/S09NjBgBg+Et6AH344Yfq6OhQTk5OsncFABhCPL8Fd/LkyZizmebmZh08eFAZGRnKyMjQ008/rWXLlikYDKqpqUmrV6/WtGnTVFhYmNDGAQBDm+cAqqur06233hp9/MnnNytWrNCGDRt06NAh/e53v9Px48cVCoW0ePFi/eQnP5Hf709c1wCAIc9zAC1cuFDOuX7X//nPf76khgAMTStWrBiQ/Tz33HMDsh8kH/eCAwCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCY8LkL3draQCQSUSAQsG4Dn8PIkSM917z33nuea6ZOneq55qqrrvJcI0mnT5+Oq264CQaDnmv2798/IPsJhUKea9ra2jzX4NKFw+ELfss1Z0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMjLBuAEPX2bNnPdf09PQkoRMk2s033+y5Jp4bi8ZzPAyy+yfjEnAGBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQ3I8WwNG7cuLjqGhsbE9yJraysrLjqHn/8cc818dxYdOXKlZ5r2tvbPddgcOIMCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAluRooB9corr3iueeKJJzzX3HXXXZ5rJOnZZ5+Nq24gpKameq5ZvXp1XPuaPXu255rW1lbPNZs3b/Zcg+GDMyAAgAkCCABgwlMAVVRU6KabblJaWpqysrK0dOlSNTQ0xGzT1dWlkpISjR07VldffbWWLVvG93cAAM7jKYCqq6tVUlKi2tpa7dmzR2fPntXixYvV2dkZ3eaRRx7R66+/rm3btqm6ulpHjx7VnXfemfDGAQBDm6eLEHbv3h3zeNOmTcrKylJ9fb0WLFigcDis3/72t9qyZYtuu+02SdLGjRt1/fXXq7a2Vl/+8pcT1zkAYEi7pM+AwuGwJCkjI0OSVF9fr7Nnz6qgoCC6zYwZMzRx4kTV1NT0+Rzd3d2KRCIxAwAw/MUdQL29vXr44Yc1f/58zZw5U5LU1tamUaNGacyYMTHbZmdnq62trc/nqaioUCAQiI4JEybE2xIAYAiJO4BKSkr07rvv6uWXX76kBsrLyxUOh6OjpaXlkp4PADA0xPWHqKWlpdq1a5f27t2r8ePHR5cHg0GdOXNGx48fjzkLam9vVzAY7PO5/H6//H5/PG0AAIYwT2dAzjmVlpZq+/btevPNN5Wbmxuzfu7cuRo5cqQqKyujyxoaGnTkyBHl5+cnpmMAwLDg6QyopKREW7Zs0c6dO5WWlhb9XCcQCGj06NEKBAJauXKlysrKlJGRofT0dD300EPKz8/nCjgAQAxPAbRhwwZJ0sKFC2OWb9y4Uffdd58k6fnnn1dKSoqWLVum7u5uFRYW6le/+lVCmgUADB8+55yzbuLTIpGIAoGAdRtIkmXLlnmu2bZtm+eaDz74wHONdO5tZK/+85//xLUvr+69917PNb///e/j2tfHH3/suaaoqMhzTV1dnecaDB3hcFjp6en9rudecAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE3F9IyoQr7feestzTUdHh+eayZMne66RpMcee8xzzfPPP++55tvf/rbnmtWrV3uuide6des813Bna3jFGRAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATPuecs27i0yKRiAKBgHUbGERuvPFGzzVvv/12XPsaOXKk55qPPvrIc01GRobnmpQU7/9efO211zzXSNLy5cs91/T09MS1Lwxf4XBY6enp/a7nDAgAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAICJEdYNABdTV1fnuebHP/5xXPsqLy/3XJOZmRnXvryqqKjwXPP888/HtS9uLIqBwBkQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEz7nnLNu4tMikYgCgYB1GwCASxQOh5Went7ves6AAAAmCCAAgAlPAVRRUaGbbrpJaWlpysrK0tKlS9XQ0BCzzcKFC+Xz+WLGqlWrEto0AGDo8xRA1dXVKikpUW1trfbs2aOzZ89q8eLF6uzsjNnu/vvvV2tra3SsXbs2oU0DAIY+T9+Iunv37pjHmzZtUlZWlurr67VgwYLo8iuvvFLBYDAxHQIAhqVL+gwoHA5LkjIyMmKWv/TSS8rMzNTMmTNVXl6uU6dO9fsc3d3dikQiMQMAcBlwcerp6XFf/epX3fz582OW//rXv3a7d+92hw4dcn/4wx/cuHHj3B133NHv86xZs8ZJYjAYDMYwG+Fw+II5EncArVq1yk2aNMm1tLRccLvKykonyTU2Nva5vqury4XD4ehoaWkxnzQGg8FgXPq4WAB5+gzoE6Wlpdq1a5f27t2r8ePHX3DbvLw8SVJjY6OmTp163nq/3y+/3x9PGwCAIcxTADnn9NBDD2n79u2qqqpSbm7uRWsOHjwoScrJyYmrQQDA8OQpgEpKSrRlyxbt3LlTaWlpamtrkyQFAgGNHj1aTU1N2rJli77yla9o7NixOnTokB555BEtWLBAs2fPTsovAAAYorx87qN+3ufbuHGjc865I0eOuAULFriMjAzn9/vdtGnT3GOPPXbR9wE/LRwOm79vyWAwGIxLHxd77edmpACApOBmpACAQYkAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYGLQBZBzzroFAEACXOz1fNAF0IkTJ6xbAAAkwMVez31ukJ1y9Pb26ujRo0pLS5PP54tZF4lENGHCBLW0tCg9Pd2oQ3vMwznMwznMwznMwzmDYR6cczpx4oRCoZBSUvo/zxkxgD19LikpKRo/fvwFt0lPT7+sD7BPMA/nMA/nMA/nMA/nWM9DIBC46DaD7i04AMDlgQACAJgYUgHk9/u1Zs0a+f1+61ZMMQ/nMA/nMA/nMA/nDKV5GHQXIQAALg9D6gwIADB8EEAAABMEEADABAEEADAxZAJo/fr1mjx5sq644grl5eXpnXfesW5pwD311FPy+XwxY8aMGdZtJd3evXu1ZMkShUIh+Xw+7dixI2a9c05PPvmkcnJyNHr0aBUUFOjw4cM2zSbRxebhvvvuO+/4KCoqsmk2SSoqKnTTTTcpLS1NWVlZWrp0qRoaGmK26erqUklJicaOHaurr75ay5YtU3t7u1HHyfF55mHhwoXnHQ+rVq0y6rhvQyKAXnnlFZWVlWnNmjXav3+/5syZo8LCQh07dsy6tQF3ww03qLW1NTr+8pe/WLeUdJ2dnZozZ47Wr1/f5/q1a9fqhRde0Isvvqh9+/bpqquuUmFhobq6uga40+S62DxIUlFRUczxsXXr1gHsMPmqq6tVUlKi2tpa7dmzR2fPntXixYvV2dkZ3eaRRx7R66+/rm3btqm6ulpHjx7VnXfeadh14n2eeZCk+++/P+Z4WLt2rVHH/XBDwLx581xJSUn0cU9PjwuFQq6iosKwq4G3Zs0aN2fOHOs2TEly27dvjz7u7e11wWDQ/exnP4suO378uPP7/W7r1q0GHQ6Mz86Dc86tWLHC3X777Sb9WDl27JiT5Kqrq51z5/7bjxw50m3bti26zfvvv+8kuZqaGqs2k+6z8+Ccc//3f//nvv/979s19TkM+jOgM2fOqL6+XgUFBdFlKSkpKigoUE1NjWFnNg4fPqxQKKQpU6bo3nvv1ZEjR6xbMtXc3Ky2traY4yMQCCgvL++yPD6qqqqUlZWl6dOn68EHH1RHR4d1S0kVDoclSRkZGZKk+vp6nT17NuZ4mDFjhiZOnDisj4fPzsMnXnrpJWVmZmrmzJkqLy/XqVOnLNrr16C7GelnffTRR+rp6VF2dnbM8uzsbP3jH/8w6spGXl6eNm3apOnTp6u1tVVPP/20brnlFr377rtKS0uzbs9EW1ubJPV5fHyy7nJRVFSkO++8U7m5uWpqatKPfvQjFRcXq6amRqmpqdbtJVxvb68efvhhzZ8/XzNnzpR07ngYNWqUxowZE7PtcD4e+poHSfrGN76hSZMmKRQK6dChQ/rhD3+ohoYGvfbaa4bdxhr0AYT/KS4ujv48e/Zs5eXladKkSXr11Ve1cuVKw84wGNx9993Rn2fNmqXZs2dr6tSpqqqq0qJFiww7S46SkhK9++67l8XnoBfS3zw88MAD0Z9nzZqlnJwcLVq0SE1NTZo6depAt9mnQf8WXGZmplJTU8+7iqW9vV3BYNCoq8FhzJgxuu6669TY2GjdiplPjgGOj/NNmTJFmZmZw/L4KC0t1a5du/TWW2/FfH1LMBjUmTNndPz48Zjth+vx0N889CUvL0+SBtXxMOgDaNSoUZo7d64qKyujy3p7e1VZWan8/HzDzuydPHlSTU1NysnJsW7FTG5uroLBYMzxEYlEtG/fvsv++Pjwww/V0dExrI4P55xKS0u1fft2vfnmm8rNzY1ZP3fuXI0cOTLmeGhoaNCRI0eG1fFwsXnoy8GDByVpcB0P1ldBfB4vv/yy8/v9btOmTe69995zDzzwgBszZoxra2uzbm1A/eAHP3BVVVWuubnZvf32266goMBlZma6Y8eOWbeWVCdOnHAHDhxwBw4ccJLcz3/+c3fgwAH3r3/9yznn3LPPPuvGjBnjdu7c6Q4dOuRuv/12l5ub606fPm3ceWJdaB5OnDjhHn30UVdTU+Oam5vdG2+84b70pS+5a6+91nV1dVm3njAPPvigCwQCrqqqyrW2tkbHqVOnotusWrXKTZw40b355puurq7O5efnu/z8fMOuE+9i89DY2OieeeYZV1dX55qbm93OnTvdlClT3IIFC4w7jzUkAsg55375y1+6iRMnulGjRrl58+a52tpa65YG3PLly11OTo4bNWqUGzdunFu+fLlrbGy0bivp3nrrLSfpvLFixQrn3LlLsZ944gmXnZ3t/H6/W7RokWtoaLBtOgkuNA+nTp1yixcvdtdcc40bOXKkmzRpkrv//vuH3T/S+vr9JbmNGzdGtzl9+rT77ne/677whS+4K6+80t1xxx2utbXVrukkuNg8HDlyxC1YsMBlZGQ4v9/vpk2b5h577DEXDodtG/8Mvo4BAGBi0H8GBAAYngggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJj4f0ygwGceqgCIAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer\n",
        "print(y_train[1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHGH8zsV8bb2",
        "outputId": "769a2744-42d6-48e2-fd69-b132af0381d1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pixel total sum\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "print(num_pixels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2DYy_Mm8xd-",
        "outputId": "80d1f864-5d3c-4a02-aa2d-6cb49b7bc623"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform pixels\n",
        "X_train2 = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test2 = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
      ],
      "metadata": {
        "id": "fKMZHOC4Gn0j"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(first_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7wiOq3rHiAq",
        "outputId": "692941db-cc52-43c0-df1b-ec1070d2834b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   36. 146. 254. 255. 251.  95.   6.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   3.  97.\n",
            "  234. 254. 254. 232. 254. 254.  35.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  89. 140. 254.\n",
            "  254. 174.  67.  33. 200. 254. 190.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 108. 253. 254. 235.\n",
            "   51.   1.   0.   0.  12. 254. 253.  56.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.  12. 216. 254. 244.  55.\n",
            "    0.   0.   0.   0.   6. 213. 254.  57.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.  25. 254. 254. 132.   0.\n",
            "    0.   0.   0.   0.   0. 168. 254.  57.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.  45. 254. 243.  34.   0.\n",
            "    0.   0.   0.   0.   0. 168. 254.  57.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0. 128. 254. 157.   0.   0.\n",
            "    0.   0.   0.   0.   0. 168. 254.  57.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.  19. 228. 254. 105.   0.   0.\n",
            "    0.   0.   0.   0.   7. 228. 254.  57.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.  58. 254. 254.  87.   0.   0.\n",
            "    0.   0.   0.   0.  10. 254. 246.  47.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.  58. 254. 254.   9.   0.   0.\n",
            "    0.   0.   0.   0.  10. 254. 210.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.  58. 254. 254.   9.   0.   0.\n",
            "    0.   0.   0.   0. 105. 254.  91.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   5. 219. 254.   9.   0.   0.\n",
            "    0.   0.   0.  24. 230. 254.  24.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0. 216. 254.   9.   0.   0.\n",
            "    0.   0.   0.  84. 254. 251.  23.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0. 216. 254.  36.   0.   0.\n",
            "    0.   0.  22. 208. 251.  94.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0. 129. 254. 120.   0.   0.\n",
            "    0.   3. 140. 254. 229.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.  83. 254. 222.  17.   0.\n",
            "    0.  91. 254. 236.  53.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.  18. 235. 254. 134.  21.\n",
            "  119. 237. 254. 124.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  53. 249. 254. 234.\n",
            "  252. 254. 172.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 116. 237. 254.\n",
            "  254. 133.  20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform values to 0 and 1\n",
        "X_train2 = X_train2 / 255\n",
        "X_test2 = X_test2 / 255"
      ],
      "metadata": {
        "id": "adCrOU_wHpen"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train2[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFhE91CgIAgZ",
        "outputId": "f5a26d6f-0f56-4949-cd3b-9ab68ca216ba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.00784314 0.07058824 0.18039216 0.53333336 0.53333336\n",
            " 0.95686275 1.         0.94509804 0.40392157 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.05882353 0.36862746 0.6392157\n",
            " 0.99215686 0.99215686 0.99215686 0.99215686 0.93333334 0.85490197\n",
            " 0.8        0.13725491 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.5137255  0.99215686 0.99215686 0.99215686 0.99215686\n",
            " 0.92941177 0.78431374 0.22352941 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.60784316 0.9647059\n",
            " 0.99215686 0.96862745 0.42352942 0.25490198 0.1764706  0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.8117647  0.99215686 0.99215686 0.9019608\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.6156863  0.99215686 0.99215686 0.49019608 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.34901962 0.99215686\n",
            " 0.98039216 0.22352941 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.34901962 0.99215686 0.96862745 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.34901962 0.99215686 0.96862745 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.34901962 0.99215686\n",
            " 0.96862745 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.08235294 0.90588236 0.9764706  0.13333334\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.88235295 0.99215686 0.90588236 0.8352941  0.8352941\n",
            " 0.48235294 0.0627451  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.6745098\n",
            " 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.74509805\n",
            " 0.24705882 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.00784314 0.45490196 0.28235295\n",
            " 0.4862745  0.81960785 0.99215686 0.99215686 0.5529412  0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.09803922\n",
            " 0.85882354 0.99215686 0.80784315 0.01176471 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.40784314 0.9647059\n",
            " 0.99215686 0.01960784 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.8352941  0.99215686 0.01960784\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.10196079 0.8862745  0.99215686 0.01960784 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.5176471  0.99215686\n",
            " 0.81960785 0.01176471 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.30588236 0.99215686 0.3372549  0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming values from train\n",
        "y_train_h = to_categorical(y_train)\n",
        "y_test_h = to_categorical(y_test)\n",
        "print(y_train[1001])\n",
        "print(y_train_h[1001])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqb9VMhhICR4",
        "outputId": "7566f43e-3fad-4272-d651-6006c20f452a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = y_test_h.shape[1]"
      ],
      "metadata": {
        "id": "8Iex8q4iIvno"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feed-forward\n",
        "model = Sequential()\n",
        "\n",
        "# Create the input layer\n",
        "model.add(InputLayer(input_shape=num_pixels))\n",
        "\n",
        "# Create the first network layer\n",
        "model.add(Dense(1024, kernel_initializer='normal', activation='relu'))\n",
        "\n",
        "# Second network layer\n",
        "model.add(Dense(2048, kernel_initializer='normal', activation='relu'))\n",
        "\n",
        "# Exit layer\n",
        "model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))"
      ],
      "metadata": {
        "id": "lynkLDUFKYgv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print informations about the created model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glLz2Zw4S8ze",
        "outputId": "dc8bf4b6-5340-411e-d2d4-486da2a07fec"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1024)              803840    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2048)              2099200   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2923530 (11.15 MB)\n",
            "Trainable params: 2923530 (11.15 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Created model compilation\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "u6ko1ZbucAqk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "result = model.fit(X_train2, y_train_h, validation_data=(X_test2, y_test_h), epochs=20, verbose=1, batch_size=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuWpZIRDisi2",
        "outputId": "e48abc0c-de1d-44cc-dedd-1c4c7893d765"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "600/600 [==============================] - 61s 99ms/step - loss: 0.1797 - accuracy: 0.9445 - val_loss: 0.0905 - val_accuracy: 0.9702\n",
            "Epoch 2/20\n",
            "600/600 [==============================] - 55s 92ms/step - loss: 0.0698 - accuracy: 0.9782 - val_loss: 0.0769 - val_accuracy: 0.9763\n",
            "Epoch 3/20\n",
            "600/600 [==============================] - 54s 90ms/step - loss: 0.0441 - accuracy: 0.9858 - val_loss: 0.0827 - val_accuracy: 0.9766\n",
            "Epoch 4/20\n",
            "600/600 [==============================] - 53s 89ms/step - loss: 0.0379 - accuracy: 0.9871 - val_loss: 0.0884 - val_accuracy: 0.9730\n",
            "Epoch 5/20\n",
            "600/600 [==============================] - 55s 91ms/step - loss: 0.0273 - accuracy: 0.9909 - val_loss: 0.0807 - val_accuracy: 0.9793\n",
            "Epoch 6/20\n",
            "600/600 [==============================] - 55s 93ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 0.0916 - val_accuracy: 0.9772\n",
            "Epoch 7/20\n",
            "600/600 [==============================] - 57s 94ms/step - loss: 0.0200 - accuracy: 0.9934 - val_loss: 0.0805 - val_accuracy: 0.9803\n",
            "Epoch 8/20\n",
            "600/600 [==============================] - 56s 93ms/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 0.0800 - val_accuracy: 0.9801\n",
            "Epoch 9/20\n",
            "600/600 [==============================] - 58s 97ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 0.1061 - val_accuracy: 0.9769\n",
            "Epoch 10/20\n",
            "600/600 [==============================] - 56s 93ms/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.0916 - val_accuracy: 0.9796\n",
            "Epoch 11/20\n",
            "600/600 [==============================] - 55s 91ms/step - loss: 0.0161 - accuracy: 0.9955 - val_loss: 0.0914 - val_accuracy: 0.9816\n",
            "Epoch 12/20\n",
            "600/600 [==============================] - 54s 90ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0947 - val_accuracy: 0.9795\n",
            "Epoch 13/20\n",
            "600/600 [==============================] - 54s 90ms/step - loss: 0.0154 - accuracy: 0.9955 - val_loss: 0.1369 - val_accuracy: 0.9737\n",
            "Epoch 14/20\n",
            "600/600 [==============================] - 55s 92ms/step - loss: 0.0138 - accuracy: 0.9961 - val_loss: 0.0998 - val_accuracy: 0.9818\n",
            "Epoch 15/20\n",
            "600/600 [==============================] - 56s 93ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.1098 - val_accuracy: 0.9808\n",
            "Epoch 16/20\n",
            "600/600 [==============================] - 55s 91ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.1285 - val_accuracy: 0.9793\n",
            "Epoch 17/20\n",
            "600/600 [==============================] - 53s 88ms/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.1369 - val_accuracy: 0.9800\n",
            "Epoch 18/20\n",
            "600/600 [==============================] - 53s 88ms/step - loss: 0.0135 - accuracy: 0.9962 - val_loss: 0.1221 - val_accuracy: 0.9811\n",
            "Epoch 19/20\n",
            "600/600 [==============================] - 55s 92ms/step - loss: 0.0171 - accuracy: 0.9959 - val_loss: 0.1216 - val_accuracy: 0.9797\n",
            "Epoch 20/20\n",
            "600/600 [==============================] - 56s 94ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.1173 - val_accuracy: 0.9815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RnBTxBbCjOX1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}